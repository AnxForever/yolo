import cv2
from ultralytics import YOLO
import os
import time
import numpy as np

class RealTimeFaceDetector:
    def __init__(self):
        # æ¨¡å‹è·¯å¾„ä¼˜å…ˆçº§è®¾ç½®
        model_paths = [
            # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šè‡ªå®šä¹‰è®­ç»ƒçš„äººè„¸æ£€æµ‹æ¨¡å‹
            r'D:\YOLO\ultralytics\runs\detect\wider_full_training_20250630_234750\weights\best.pt',
            # ç¬¬äºŒä¼˜å…ˆçº§ï¼šå½“å‰ç›®å½•ä¸‹çš„è‡ªå®šä¹‰æ¨¡å‹
            './models/best.pt',
            './best.pt',
            # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šé€šç”¨YOLO11æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
            'yolo11n.pt'
        ]
        
        self.model_path = None
        self.model_type = "unknown"
        
        # æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹
        for path in model_paths:
            if path == 'yolo11n.pt':
                # YOLO11é€šç”¨æ¨¡å‹ï¼Œultralyticsä¼šè‡ªåŠ¨ä¸‹è½½
                self.model_path = path
                self.model_type = "é€šç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹"
                print(f"ğŸ¯ Using general YOLO11 model: {path}")
                break
            elif os.path.exists(path):
                self.model_path = path
                if 'wider' in path or 'face' in path:
                    self.model_type = "ä¸“ç”¨äººè„¸æ£€æµ‹æ¨¡å‹"
                else:
                    self.model_type = "è‡ªå®šä¹‰æ¨¡å‹"
                print(f"ğŸ¯ Found custom model: {path}")
                break
        
        if not self.model_path:
            print("âŒ Error: No suitable model found!")
            exit()
        
        # åŠ è½½YOLOæ¨¡å‹
        print(f"ğŸ¤– Loading {self.model_type}...")
        try:
            self.model = YOLO(self.model_path)
            print("âœ… Model loaded successfully.")
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            print("ğŸ”„ Trying to download YOLO11n model...")
            self.model = YOLO('yolo11n.pt')
            self.model_type = "é€šç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹"
            print("âœ… YOLO11n model loaded successfully.")
        
        # Initialize camera variables
        self.camera_index = 0
        self.cap = None
        self.available_cameras = []
        
        # Performance tracking
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0
        
        # Find available cameras
        self.find_available_cameras()
        
        # Initialize camera
        self.init_camera()
    
    def find_available_cameras(self):
        """æ£€æµ‹å¯ç”¨çš„æ‘„åƒå¤´"""
        print("ğŸ” Searching for available cameras...")
        self.available_cameras = []
        
        # æ£€æµ‹æœ€å¤š10ä¸ªæ‘„åƒå¤´
        for i in range(10):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    # è·å–æ‘„åƒå¤´ä¿¡æ¯
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    
                    self.available_cameras.append({
                        'index': i,
                        'width': width,
                        'height': height,
                        'fps': fps
                    })
                    print(f"ğŸ“· Camera {i}: {width}x{height} @ {fps:.1f}FPS")
                cap.release()
        
        if not self.available_cameras:
            print("âŒ No cameras found!")
            exit()
        
        print(f"âœ… Found {len(self.available_cameras)} camera(s)")
    
    def init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        if self.cap is not None:
            self.cap.release()
        
        self.cap = cv2.VideoCapture(self.camera_index)
        
        if not self.cap.isOpened():
            print(f"âŒ Error: Could not open camera {self.camera_index}")
            return False
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        print(f"âœ… Camera {self.camera_index} opened successfully")
        return True
    
    def switch_camera(self):
        """åˆ‡æ¢æ‘„åƒå¤´"""
        if len(self.available_cameras) <= 1:
            print("âš ï¸ Only one camera available")
            return
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨æ‘„åƒå¤´
        current_idx = 0
        for i, cam in enumerate(self.available_cameras):
            if cam['index'] == self.camera_index:
                current_idx = i
                break
        
        next_idx = (current_idx + 1) % len(self.available_cameras)
        self.camera_index = self.available_cameras[next_idx]['index']
        
        print(f"ğŸ”„ Switching to camera {self.camera_index}")
        self.init_camera()
    
    def calculate_fps(self):
        """è®¡ç®—FPS"""
        self.fps_counter += 1
        
        if self.fps_counter >= 30:  # æ¯30å¸§è®¡ç®—ä¸€æ¬¡FPS
            end_time = time.time()
            self.current_fps = self.fps_counter / (end_time - self.fps_start_time)
            self.fps_counter = 0
            self.fps_start_time = end_time
    
    def draw_info_panel(self, frame, face_count):
        """ç»˜åˆ¶ä¿¡æ¯é¢æ¿"""
        height, width = frame.shape[:2]
        
        # åˆ›å»ºåŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        info_height = 120
        cv2.rectangle(overlay, (0, 0), (width, info_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # æ˜¾ç¤ºä¿¡æ¯
        font = cv2.FONT_HERSHEY_SIMPLEX
        
        # æ ‡é¢˜
        cv2.putText(frame, "Real-time Face Detection", (10, 25), 
                   font, 0.8, (0, 255, 255), 2)
        
        # äººè„¸æ•°é‡ - å¤§å·æ˜¾ç¤º
        face_text = f"Faces Detected: {face_count}"
        cv2.putText(frame, face_text, (10, 55), 
                   font, 0.7, (0, 255, 0), 2)
        
        # FPS
        fps_text = f"FPS: {self.current_fps:.1f}"
        cv2.putText(frame, fps_text, (10, 80), 
                   font, 0.6, (255, 255, 255), 1)
        
        # æ‘„åƒå¤´ä¿¡æ¯
        cam_text = f"Camera: {self.camera_index} ({len(self.available_cameras)} available)"
        cv2.putText(frame, cam_text, (10, 100), 
                   font, 0.6, (255, 255, 255), 1)
        
        # æ¨¡å‹ä¿¡æ¯
        model_text = f"Model: {self.model_type}"
        cv2.putText(frame, model_text, (10, 115), 
                   font, 0.5, (200, 200, 200), 1)
        
        # åœ¨å³ä¾§æ˜¾ç¤ºæ§åˆ¶æç¤º
        controls = [
            "Controls:",
            "Q - Quit",
            "C - Switch Camera",
            "S - Screenshot"
        ]
        
        start_x = width - 200
        for i, control in enumerate(controls):
            y = 25 + i * 20
            color = (255, 255, 0) if i == 0 else (255, 255, 255)
            cv2.putText(frame, control, (start_x, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        return frame
    
    def save_screenshot(self, frame, face_count):
        """ä¿å­˜æˆªå›¾"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"face_detection_screenshot_{timestamp}_faces_{face_count}.jpg"
        cv2.imwrite(filename, frame)
        print(f"ğŸ“¸ Screenshot saved: {filename}")
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("\nğŸš€ Starting real-time face detection...")
        print("ğŸ“‹ Controls:")
        print("   Q - Quit")
        print("   C - Switch Camera") 
        print("   S - Take Screenshot")
        print("-" * 50)
        
        screenshot_count = 0
        
        while True:
            # è¯»å–å¸§
            if self.cap is None or not self.cap.isOpened():
                print("âŒ Error: Camera not available.")
                break
                
            ret, frame = self.cap.read()
            if not ret:
                print("âŒ Error: Failed to capture frame.")
                break
            
            # ç¿»è½¬å›¾åƒï¼ˆé•œåƒæ•ˆæœï¼‰
            frame = cv2.flip(frame, 1)
            
            # æ‰§è¡Œäººè„¸æ£€æµ‹
            results = self.model(frame, conf=0.25, verbose=False)
            
            # è·å–æ£€æµ‹ç»“æœ
            detections = results[0].boxes
            face_count = len(detections) if detections is not None else 0
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            annotated_frame = results[0].plot()
            
            # ç¿»è½¬æ ‡æ³¨åçš„å›¾åƒä»¥åŒ¹é…åŸå§‹ç¿»è½¬
            annotated_frame = cv2.flip(annotated_frame, 1)
            
            # ç»˜åˆ¶ä¿¡æ¯é¢æ¿
            annotated_frame = self.draw_info_panel(annotated_frame, face_count)
            
            # è®¡ç®—FPS
            self.calculate_fps()
            
            # æ˜¾ç¤ºå›¾åƒ
            cv2.imshow('Real-time Face Detection (Custom Model)', annotated_frame)
            
            # å¤„ç†æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q') or key == ord('Q'):
                print("ğŸ‘‹ Quitting...")
                break
            elif key == ord('c') or key == ord('C'):
                self.switch_camera()
            elif key == ord('s') or key == ord('S'):
                screenshot_count += 1
                self.save_screenshot(annotated_frame, face_count)
        
        # æ¸…ç†èµ„æº
        self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.cap is not None:
            self.cap.release()
        cv2.destroyAllWindows()
        print("ğŸ§¹ Resources cleaned up. Goodbye!")

def main():
    """ä¸»å‡½æ•°"""
    try:
        detector = RealTimeFaceDetector()
        detector.run()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Program interrupted by user")
    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    main() 