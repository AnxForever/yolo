import os
import cv2
import json
import time
import base64
from datetime import datetime
from flask import Flask, render_template, Response, jsonify, request
from flask_cors import CORS
from threading import Thread, Event
import queue
import logging

from advanced_face_recognition import AdvancedFaceRecognitionSystem

app = Flask(__name__)
CORS(app)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

class WebFaceRecognitionSystem:
    def __init__(self):
        self.face_system = AdvancedFaceRecognitionSystem()
        self.is_running = False
        self.current_frame = None
        self.recognition_results = []
        self.frame_queue = queue.Queue(maxsize=2)
        self.auto_capture_targets = set()  # éœ€è¦è‡ªåŠ¨æŠ“æ‹çš„äººå‘˜åå•
        self.capture_cooldown = {}  # æŠ“æ‹å†·å´æ—¶é—´ï¼ˆé¿å…è¿ç»­æŠ“æ‹åŒä¸€äººï¼‰
        self.capture_interval = 5  # å¯¹åŒä¸€äººçš„æŠ“æ‹é—´éš”ï¼ˆç§’ï¼‰
        self.capture_history = []  # æŠ“æ‹å†å²è®°å½•
        
        # åˆ›å»ºæŠ“æ‹ä¿å­˜ç›®å½•
        self.auto_capture_dir = os.path.join(self.face_system.script_dir, "auto_captures")
        os.makedirs(self.auto_capture_dir, exist_ok=True)
        
    def generate_frames(self):
        """ç”Ÿæˆè§†é¢‘æµå¸§"""
        cap = cv2.VideoCapture(self.face_system.current_camera_index, cv2.CAP_DSHOW)
        if not cap.isOpened():
            return
            
        while self.is_running:
            ret, frame = cap.read()
            if not ret:
                break
                
            # è¿›è¡Œäººè„¸æ£€æµ‹å’Œè¯†åˆ«
            results = self.process_frame(frame)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æŠ“æ‹
            self.check_auto_capture(frame, results)
            
            # åœ¨å¸§ä¸Šç»˜åˆ¶è¯†åˆ«ç»“æœ
            frame = self.draw_results_on_frame(frame, results)
            
            # ç¼–ç ä¸ºJPEG
            ret, buffer = cv2.imencode('.jpg', frame)
            if ret:
                frame_bytes = buffer.tobytes()
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        
        cap.release()
        
    def process_frame(self, frame):
        """å¤„ç†å•å¸§ï¼Œè¿”å›è¯†åˆ«ç»“æœ"""
        face_locations = self.face_system.detect_faces_yolo(frame)
        face_names = []
        face_emotions = []
        
        if face_locations:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            face_names = self.face_system.recognize_faces(rgb_frame, face_locations)
            face_emotions = self.face_system._analyze_emotions(frame, face_locations)
        
        results = {
            'face_locations': face_locations,
            'face_names': face_names,
            'face_emotions': face_emotions,
            'face_count': len(face_locations),
            'timestamp': datetime.now().isoformat()
        }
        
        self.recognition_results = results
        return results
    
    def check_auto_capture(self, frame, results):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æŠ“æ‹"""
        if not self.auto_capture_targets:
            return
            
        current_time = time.time()
        
        for i, name in enumerate(results['face_names']):
            if name in self.auto_capture_targets:
                # æ£€æŸ¥å†·å´æ—¶é—´
                last_capture_time = self.capture_cooldown.get(name, 0)
                if current_time - last_capture_time >= self.capture_interval:
                    self.capture_person(frame, results, i, name)
                    self.capture_cooldown[name] = current_time
    
    def capture_person(self, frame, results, person_index, person_name):
        """è‡ªåŠ¨æŠ“æ‹æŒ‡å®šäººå‘˜"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            emotion = results['face_emotions'][person_index] if person_index < len(results['face_emotions']) else "unknown"
            
            filename = f"auto_capture_{person_name}_{emotion}_{timestamp}.jpg"
            filepath = os.path.join(self.auto_capture_dir, filename)
            
            cv2.imwrite(filepath, frame)
            
            # è®°å½•æŠ“æ‹å†å²
            capture_record = {
                'person_name': person_name,
                'emotion': emotion,
                'timestamp': datetime.now().isoformat(),
                'filename': filename,
                'filepath': filepath
            }
            self.capture_history.append(capture_record)
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(self.capture_history) > 100:
                self.capture_history = self.capture_history[-100:]
                
            app.logger.info(f"è‡ªåŠ¨æŠ“æ‹: {person_name} ({emotion}) -> {filename}")
            
        except Exception as e:
            app.logger.error(f"è‡ªåŠ¨æŠ“æ‹å¤±è´¥: {e}")
    
    def draw_results_on_frame(self, frame, results):
        """åœ¨å¸§ä¸Šç»˜åˆ¶è¯†åˆ«ç»“æœ"""
        face_locations = results['face_locations']
        face_names = results['face_names']
        face_emotions = results['face_emotions']
        
        for i, (top, right, bottom, left) in enumerate(face_locations):
            # è·å–äººåå’Œæƒ…ç»ª
            name = face_names[i] if i < len(face_names) else "Unknown"
            emotion = face_emotions[i] if i < len(face_emotions) else ""
            
            # ç»˜åˆ¶äººè„¸æ¡†
            color = (0, 255, 0) if name != "æœªçŸ¥" else (0, 0, 255)
            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
            
            # å‡†å¤‡æ˜¾ç¤ºæ–‡æœ¬
            display_text = name
            if emotion:
                display_text = f"{name} ({emotion})"
                
            # å¦‚æœæ˜¯è‡ªåŠ¨æŠ“æ‹ç›®æ ‡ï¼Œæ·»åŠ ç‰¹æ®Šæ ‡è®°
            if name in self.auto_capture_targets:
                display_text += " [AUTO]"
                
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)
            
            # ç»˜åˆ¶æ–‡æœ¬
            cv2.putText(frame, display_text, (left + 6, bottom - 6), 
                       cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)
        
        return frame

# åˆ›å»ºå…¨å±€Webç³»ç»Ÿå®ä¾‹
web_system = WebFaceRecognitionSystem()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    """è§†é¢‘æµç«¯ç‚¹"""
    return Response(web_system.generate_frames(),
                   mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/start_recognition', methods=['POST'])
def start_recognition():
    """å¯åŠ¨äººè„¸è¯†åˆ«"""
    if not web_system.is_running:
        web_system.is_running = True
        return jsonify({'status': 'success', 'message': 'äººè„¸è¯†åˆ«å·²å¯åŠ¨'})
    return jsonify({'status': 'error', 'message': 'äººè„¸è¯†åˆ«å·²åœ¨è¿è¡Œ'})

@app.route('/api/stop_recognition', methods=['POST'])
def stop_recognition():
    """åœæ­¢äººè„¸è¯†åˆ«"""
    web_system.is_running = False
    return jsonify({'status': 'success', 'message': 'äººè„¸è¯†åˆ«å·²åœæ­¢'})

@app.route('/api/recognition_status')
def recognition_status():
    """è·å–è¯†åˆ«çŠ¶æ€"""
    return jsonify({
        'is_running': web_system.is_running,
        'results': web_system.recognition_results,
        'auto_capture_targets': list(web_system.auto_capture_targets)
    })

@app.route('/api/database_info')
def database_info():
    """è·å–æ•°æ®åº“ä¿¡æ¯"""
    known_names = list(set(web_system.face_system.known_face_names))
    return jsonify({
        'known_people': known_names,
        'total_people': len(known_names),
        'total_features': len(web_system.face_system.known_face_encodings)
    })

@app.route('/api/update_database', methods=['POST'])
def update_database():
    """æ›´æ–°äººè„¸æ•°æ®åº“"""
    data = request.get_json()
    augment = data.get('augment', False)
    
    try:
        web_system.face_system.rescan_and_encode_database(augment=augment)
        web_system.face_system.load_face_database()
        return jsonify({'status': 'success', 'message': 'æ•°æ®åº“æ›´æ–°æˆåŠŸ'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'æ•°æ®åº“æ›´æ–°å¤±è´¥: {str(e)}'})

@app.route('/api/auto_capture_targets', methods=['GET', 'POST'])
def auto_capture_targets():
    """ç®¡ç†è‡ªåŠ¨æŠ“æ‹ç›®æ ‡"""
    if request.method == 'GET':
        return jsonify({'targets': list(web_system.auto_capture_targets)})
    
    elif request.method == 'POST':
        data = request.get_json()
        action = data.get('action')
        person_name = data.get('person_name')
        
        if action == 'add' and person_name:
            web_system.auto_capture_targets.add(person_name)
            return jsonify({'status': 'success', 'message': f'å·²æ·»åŠ  {person_name} åˆ°è‡ªåŠ¨æŠ“æ‹åˆ—è¡¨'})
        
        elif action == 'remove' and person_name:
            web_system.auto_capture_targets.discard(person_name)
            return jsonify({'status': 'success', 'message': f'å·²ä»è‡ªåŠ¨æŠ“æ‹åˆ—è¡¨ç§»é™¤ {person_name}'})
        
        elif action == 'clear':
            web_system.auto_capture_targets.clear()
            return jsonify({'status': 'success', 'message': 'å·²æ¸…ç©ºè‡ªåŠ¨æŠ“æ‹åˆ—è¡¨'})
        
        return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ“ä½œ'})

@app.route('/api/capture_history')
def capture_history():
    """è·å–æŠ“æ‹å†å²"""
    return jsonify({
        'history': web_system.capture_history[-50:],  # è¿”å›æœ€è¿‘50æ¡è®°å½•
        'total_captures': len(web_system.capture_history)
    })

@app.route('/api/manual_capture', methods=['POST'])
def manual_capture():
    """æ‰‹åŠ¨æŠ“æ‹"""
    if web_system.current_frame is not None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"manual_capture_{timestamp}.jpg"
        filepath = os.path.join(web_system.auto_capture_dir, filename)
        
        cv2.imwrite(filepath, web_system.current_frame)
        return jsonify({'status': 'success', 'message': f'æ‰‹åŠ¨æŠ“æ‹æˆåŠŸ: {filename}'})
    
    return jsonify({'status': 'error', 'message': 'æ— æ³•è·å–å½“å‰ç”»é¢'})

@app.route('/api/switch_camera', methods=['POST'])
def switch_camera():
    """åˆ‡æ¢æ‘„åƒå¤´"""
    try:
        web_system.face_system._switch_camera()
        return jsonify({'status': 'success', 'message': f'å·²åˆ‡æ¢åˆ°æ‘„åƒå¤´ {web_system.face_system.current_camera_index}'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'åˆ‡æ¢æ‘„åƒå¤´å¤±è´¥: {str(e)}'})

if __name__ == '__main__':
    print("ğŸŒ æ­£åœ¨å¯åŠ¨Webäººè„¸è¯†åˆ«ç³»ç»Ÿ...")
    print("ğŸ“± è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:5000")
    app.run(host='0.0.0.0', port=5000, debug=True) 