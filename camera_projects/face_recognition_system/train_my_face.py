import cv2
import face_recognition
import os
import pickle
import numpy as np

def train_face_from_directory():
    """ä»face_databaseç›®å½•è®­ç»ƒäººè„¸è¯†åˆ«"""
    
    # è®¾ç½®è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    face_database_dir = os.path.join(script_dir, "face_database")
    encodings_file = os.path.join(face_database_dir, "face_encodings.pkl")
    
    print("="*60)
    print("ğŸ¯ äººè„¸è¯†åˆ«è®­ç»ƒç³»ç»Ÿ")
    print("="*60)
    print(f"ğŸ“ è®­ç»ƒæ•°æ®ç›®å½•: {face_database_dir}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(face_database_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {face_database_dir}")
        return
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = []
    supported_formats = ['.jpg', '.jpeg', '.png', '.bmp']
    
    for file in os.listdir(face_database_dir):
        if any(file.lower().endswith(fmt) for fmt in supported_formats):
            image_files.append(file)
    
    if not image_files:
        print("âŒ åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"ğŸ“· æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ:")
    for i, img in enumerate(image_files, 1):
        print(f"   {i}. {img}")
    
    # è·å–ç”¨æˆ·å§“å
    user_name = input("\nğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„å§“å (ç”¨äºè¯†åˆ«æ ‡è¯†): ").strip()
    if not user_name:
        user_name = "ç”¨æˆ·"
    
    print(f"\nğŸ” å¼€å§‹è®­ç»ƒäººè„¸è¯†åˆ«ï¼Œæ ‡è¯†ä¸º: {user_name}")
    print("-"*60)
    
    # å­˜å‚¨æ‰€æœ‰äººè„¸ç¼–ç 
    all_encodings = []
    valid_images = []
    
    for i, image_file in enumerate(image_files, 1):
        image_path = os.path.join(face_database_dir, image_file)
        print(f"ğŸ“¸ å¤„ç†ç¬¬ {i}/{len(image_files)} å¼ å›¾åƒ: {image_file}")
        
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print(f"   âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
                continue
            
            # è½¬æ¢BGRåˆ°RGB (face_recognitionä½¿ç”¨RGBæ ¼å¼)
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # æ£€æµ‹äººè„¸ä½ç½®
            face_locations = face_recognition.face_locations(rgb_image)
            
            if len(face_locations) == 0:
                print(f"   âŒ æœªæ£€æµ‹åˆ°äººè„¸")
                continue
            elif len(face_locations) > 1:
                print(f"   âš ï¸  æ£€æµ‹åˆ° {len(face_locations)} ä¸ªäººè„¸ï¼Œä½¿ç”¨æœ€å¤§çš„ä¸€ä¸ª")
                # é€‰æ‹©æœ€å¤§çš„äººè„¸
                areas = []
                for top, right, bottom, left in face_locations:
                    area = (bottom - top) * (right - left)
                    areas.append(area)
                max_area_index = np.argmax(areas)
                face_locations = [face_locations[max_area_index]]
            
            # æå–äººè„¸ç‰¹å¾
            face_encodings = face_recognition.face_encodings(rgb_image, face_locations)
            
            if len(face_encodings) > 0:
                encoding = face_encodings[0]
                all_encodings.append(encoding)
                valid_images.append(image_file)
                print(f"   âœ… æˆåŠŸæå–äººè„¸ç‰¹å¾")
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                top, right, bottom, left = face_locations[0]
                cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(image, f"{user_name} - {i}", (left, top-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºå›¾åƒ2ç§’
                cv2.imshow(f'è®­ç»ƒä¸­: {image_file}', image)
                cv2.waitKey(2000)
                cv2.destroyAllWindows()
            else:
                print(f"   âŒ æ— æ³•æå–äººè„¸ç‰¹å¾")
                
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
    
    print("-"*60)
    print(f"ğŸ“Š è®­ç»ƒç»“æœç»Ÿè®¡:")
    print(f"   æ€»å›¾åƒæ•°é‡: {len(image_files)}")
    print(f"   æˆåŠŸè®­ç»ƒ: {len(valid_images)}")
    print(f"   å¤±è´¥æ•°é‡: {len(image_files) - len(valid_images)}")
    
    if len(all_encodings) == 0:
        print("\nâŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•äººè„¸ç‰¹å¾ï¼Œè®­ç»ƒå¤±è´¥ï¼")
        return
    
    # è®¡ç®—å¹³å‡ç¼–ç ï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥ä¿å­˜æ‰€æœ‰ç¼–ç ï¼‰
    use_average = len(all_encodings) > 1
    if use_average:
        print(f"\nğŸ§® è®¡ç®—å¹³å‡äººè„¸ç‰¹å¾...")
        average_encoding = np.mean(all_encodings, axis=0)
        final_encodings = [average_encoding]
        print("   âœ… ä½¿ç”¨å¹³å‡ç‰¹å¾ä½œä¸ºæœ€ç»ˆæ¨¡å‹")
    else:
        final_encodings = all_encodings
        print("   âœ… ä½¿ç”¨å•ä¸€ç‰¹å¾ä½œä¸ºæœ€ç»ˆæ¨¡å‹")
    
    # ä¿å­˜äººè„¸æ•°æ®åº“
    try:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®åº“
        existing_encodings = []
        existing_names = []
        
        if os.path.exists(encodings_file):
            try:
                with open(encodings_file, 'rb') as f:
                    data = pickle.load(f)
                    existing_encodings = data.get('encodings', [])
                    existing_names = data.get('names', [])
                print(f"ğŸ“‹ å‘ç°ç°æœ‰æ•°æ®åº“ï¼ŒåŒ…å« {len(existing_names)} ä¸ªå·²æ³¨å†Œäººå‘˜")
            except:
                print("âš ï¸  ç°æœ‰æ•°æ®åº“æ–‡ä»¶æŸåï¼Œå°†åˆ›å»ºæ–°æ•°æ®åº“")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåç”¨æˆ·
        if user_name in existing_names:
            choice = input(f"âš ï¸  ç”¨æˆ· '{user_name}' å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–? (y/n): ").strip().lower()
            if choice == 'y' or choice == 'yes':
                # ç§»é™¤æ—§æ•°æ®
                user_indices = [i for i, name in enumerate(existing_names) if name == user_name]
                for index in reversed(user_indices):  # ä»åå‘å‰åˆ é™¤
                    existing_encodings.pop(index)
                    existing_names.pop(index)
                print(f"ğŸ—‘ï¸  å·²ç§»é™¤æ—§çš„ '{user_name}' æ•°æ®")
            else:
                print("âŒ è®­ç»ƒå·²å–æ¶ˆ")
                return
        
        # æ·»åŠ æ–°çš„ç¼–ç 
        for encoding in final_encodings:
            existing_encodings.append(encoding)
            existing_names.append(user_name)
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®åº“
        data = {
            'encodings': existing_encodings,
            'names': existing_names
        }
        
        with open(encodings_file, 'wb') as f:
            pickle.dump(data, f)
        
        print(f"\nâœ… äººè„¸è¯†åˆ«è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {encodings_file}")
        print(f"ğŸ‘¥ æ•°æ®åº“ç°åœ¨åŒ…å« {len(existing_names)} ä¸ªå·²æ³¨å†Œäººå‘˜")
        print(f"ğŸ¯ æ‚¨çš„è¯†åˆ«æ ‡è¯†: {user_name}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        from collections import Counter
        name_counts = Counter(existing_names)
        print(f"\nğŸ“ˆ æ•°æ®åº“è¯¦æƒ…:")
        for name, count in name_counts.items():
            print(f"   {name}: {count} ä¸ªç‰¹å¾å‘é‡")
        
        print(f"\nğŸ‰ ç°åœ¨å¯ä»¥ä½¿ç”¨å®æ—¶äººè„¸è¯†åˆ«åŠŸèƒ½æ¥è¯†åˆ«æ‚¨äº†ï¼")
        
    except Exception as e:
        print(f"\nâŒ ä¿å­˜æ•°æ®åº“å¤±è´¥: {e}")

if __name__ == "__main__":
    train_face_from_directory() 