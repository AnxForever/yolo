import os
import cv2
import time
import threading
import queue
import logging
from datetime import datetime
from flask import Flask, render_template, Response, jsonify, request
from flask_cors import CORS

from advanced_face_recognition import AdvancedFaceRecognitionSystem

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

class SimpleOptimizedSystem:
    def __init__(self):
        print("ğŸš€ åˆå§‹åŒ–ç³»ç»Ÿ...")
        self.face_system = AdvancedFaceRecognitionSystem()
        
        # æ‘„åƒå¤´ç›¸å…³
        self.cap = None
        self.is_running = False
        self.current_frame = None
        self.frame_lock = threading.Lock()
        
        # è¯†åˆ«ç»“æœ
        self.latest_results = {
            'face_count': 0,
            'face_names': [],
            'face_emotions': [],
            'face_locations': []
        }
        
        # è‡ªåŠ¨æŠ“æ‹
        self.auto_capture_targets = set()
        self.capture_cooldown = {}
        self.capture_interval = 5
        self.capture_history = []
        
        # åˆ›å»ºç›®å½•
        self.auto_capture_dir = os.path.join(self.face_system.script_dir, "auto_captures")
        os.makedirs(self.auto_capture_dir, exist_ok=True)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps = 0
        self.last_fps_time = time.time()
        self.frame_count = 0
        
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        try:
            if self.is_running:
                return True
                
            print("ğŸ“¹ æ­£åœ¨å¯åŠ¨æ‘„åƒå¤´...")
            self.cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
            
            if not self.cap or not self.cap.isOpened():
                print("âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            self.is_running = True
            print("âœ… æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ‘„åƒå¤´å¯åŠ¨å¼‚å¸¸: {e}")
            return False
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.is_running = False
        if self.cap:
            self.cap.release()
            self.cap = None
        print("ğŸ›‘ æ‘„åƒå¤´å·²åœæ­¢")
    
    def generate_frames(self):
        """ç”Ÿæˆè§†é¢‘æµ"""
        if not self.start_camera():
            return
            
        print("ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘æµ...")
        
        while self.is_running and self.cap:
            try:
                ret, frame = self.cap.read()
                if not ret:
                    print("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    time.sleep(0.1)
                    continue
                
                # æ›´æ–°å½“å‰å¸§
                with self.frame_lock:
                    self.current_frame = frame.copy()
                
                # è¿›è¡Œäººè„¸æ£€æµ‹å’Œè¯†åˆ«
                processed_frame = self.process_frame(frame)
                
                # è®¡ç®—FPS
                self.update_fps()
                
                # åœ¨ç”»é¢ä¸Šç»˜åˆ¶FPS
                cv2.putText(processed_frame, f"FPS: {self.fps:.1f}", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # ç¼–ç ä¸ºJPEG
                ret, buffer = cv2.imencode('.jpg', processed_frame, 
                                         [cv2.IMWRITE_JPEG_QUALITY, 85])
                
                if ret:
                    frame_bytes = buffer.tobytes()
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                
            except Exception as e:
                print(f"âŒ è§†é¢‘æµç”Ÿæˆé”™è¯¯: {e}")
                time.sleep(0.1)
        
        print("ğŸ è§†é¢‘æµå·²åœæ­¢")
    
    def process_frame(self, frame):
        """å¤„ç†å¸§ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            # æ¯5å¸§å¤„ç†ä¸€æ¬¡ï¼Œæé«˜æ€§èƒ½
            if self.frame_count % 5 != 0:
                self.frame_count += 1
                return frame
            
            # äººè„¸æ£€æµ‹
            face_locations = self.face_system.detect_faces_yolo(frame)
            face_names = []
            face_emotions = []
            
            if face_locations:
                # è½¬æ¢é¢œè‰²ç©ºé—´
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # äººè„¸è¯†åˆ«
                face_names = self.face_system.recognize_faces(rgb_frame, face_locations)
                
                # ç®€åŒ–æƒ…ç»ªåˆ†æ - å¯é€‰æ‹©æ€§ç¦ç”¨
                try:
                    face_emotions = self.face_system._analyze_emotions(frame, face_locations)
                except:
                    face_emotions = [""] * len(face_locations)
            
            # æ›´æ–°ç»“æœ
            self.latest_results = {
                'face_count': len(face_locations),
                'face_names': face_names,
                'face_emotions': face_emotions,
                'face_locations': face_locations
            }
            
            # æ£€æŸ¥è‡ªåŠ¨æŠ“æ‹
            self.check_auto_capture(frame, face_names, face_emotions)
            
            # ç»˜åˆ¶ç»“æœ
            frame = self.draw_results(frame, face_locations, face_names, face_emotions)
            
            self.frame_count += 1
            return frame
            
        except Exception as e:
            print(f"âŒ å¸§å¤„ç†é”™è¯¯: {e}")
            return frame
    
    def draw_results(self, frame, face_locations, face_names, face_emotions):
        """ç»˜åˆ¶è¯†åˆ«ç»“æœ"""
        for i, (top, right, bottom, left) in enumerate(face_locations):
            # è·å–ä¿¡æ¯
            name = face_names[i] if i < len(face_names) else "Unknown"
            emotion = face_emotions[i] if i < len(face_emotions) else ""
            
            # è®¾ç½®é¢œè‰²
            color = (0, 255, 0) if name != "æœªçŸ¥" else (0, 0, 255)
            if name in self.auto_capture_targets:
                color = (255, 165, 0)  # æ©™è‰²è¡¨ç¤ºè‡ªåŠ¨æŠ“æ‹ç›®æ ‡
            
            # ç»˜åˆ¶äººè„¸æ¡†
            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
            
            # å‡†å¤‡æ–‡æœ¬
            display_text = name
            if emotion:
                display_text = f"{name} ({emotion})"
            if name in self.auto_capture_targets:
                display_text += " [AUTO]"
            
            # ç»˜åˆ¶æ ‡ç­¾
            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)
            cv2.putText(frame, display_text, (left + 6, bottom - 6), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return frame
    
    def check_auto_capture(self, frame, face_names, face_emotions):
        """æ£€æŸ¥è‡ªåŠ¨æŠ“æ‹"""
        if not self.auto_capture_targets:
            return
        
        current_time = time.time()
        
        for i, name in enumerate(face_names):
            if name in self.auto_capture_targets:
                last_capture = self.capture_cooldown.get(name, 0)
                if current_time - last_capture >= self.capture_interval:
                    self.capture_person(frame, name, face_emotions[i] if i < len(face_emotions) else "")
                    self.capture_cooldown[name] = current_time
    
    def capture_person(self, frame, person_name, emotion):
        """è‡ªåŠ¨æŠ“æ‹"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"auto_capture_{person_name}_{emotion}_{timestamp}.jpg"
            filepath = os.path.join(self.auto_capture_dir, filename)
            
            cv2.imwrite(filepath, frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            record = {
                'person_name': person_name,
                'emotion': emotion,
                'timestamp': datetime.now().isoformat(),
                'filename': filename
            }
            
            self.capture_history.append(record)
            if len(self.capture_history) > 100:
                self.capture_history = self.capture_history[-100:]
            
            print(f"ğŸ“¸ è‡ªåŠ¨æŠ“æ‹: {person_name} ({emotion})")
            
        except Exception as e:
            print(f"âŒ è‡ªåŠ¨æŠ“æ‹å¤±è´¥: {e}")
    
    def update_fps(self):
        """æ›´æ–°FPS"""
        current_time = time.time()
        if current_time - self.last_fps_time >= 1.0:
            self.fps = self.frame_count / (current_time - self.last_fps_time)
            self.frame_count = 0
            self.last_fps_time = current_time

# åˆ›å»ºå…¨å±€ç³»ç»Ÿå®ä¾‹
system = SimpleOptimizedSystem()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    """è§†é¢‘æµç«¯ç‚¹"""
    print("ğŸ¥ è¯·æ±‚è§†é¢‘æµ...")
    return Response(system.generate_frames(),
                   mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/start_recognition', methods=['POST'])
def start_recognition():
    if system.start_camera():
        return jsonify({'status': 'success', 'message': 'è¯†åˆ«å·²å¯åŠ¨'})
    return jsonify({'status': 'error', 'message': 'å¯åŠ¨å¤±è´¥'})

@app.route('/api/stop_recognition', methods=['POST'])
def stop_recognition():
    system.stop_camera()
    return jsonify({'status': 'success', 'message': 'è¯†åˆ«å·²åœæ­¢'})

@app.route('/api/recognition_status')
def recognition_status():
    return jsonify({
        'is_running': system.is_running,
        'results': system.latest_results,
        'auto_capture_targets': list(system.auto_capture_targets),
        'fps': system.fps
    })

@app.route('/api/database_info')
def database_info():
    known_names = list(set(system.face_system.known_face_names))
    return jsonify({
        'known_people': known_names,
        'total_people': len(known_names),
        'total_features': len(system.face_system.known_face_encodings)
    })

@app.route('/api/update_database', methods=['POST'])
def update_database():
    data = request.get_json()
    augment = data.get('augment', False)
    
    try:
        system.face_system.rescan_and_encode_database(augment=augment)
        system.face_system.load_face_database()
        return jsonify({'status': 'success', 'message': 'æ•°æ®åº“æ›´æ–°æˆåŠŸ'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'æ›´æ–°å¤±è´¥: {str(e)}'})

@app.route('/api/auto_capture_targets', methods=['GET', 'POST'])
def auto_capture_targets():
    if request.method == 'GET':
        return jsonify({'targets': list(system.auto_capture_targets)})
    
    data = request.get_json()
    action = data.get('action')
    person_name = data.get('person_name')
    
    if action == 'add' and person_name:
        system.auto_capture_targets.add(person_name)
        return jsonify({'status': 'success', 'message': f'å·²æ·»åŠ  {person_name}'})
    elif action == 'remove' and person_name:
        system.auto_capture_targets.discard(person_name)
        return jsonify({'status': 'success', 'message': f'å·²ç§»é™¤ {person_name}'})
    elif action == 'clear':
        system.auto_capture_targets.clear()
        return jsonify({'status': 'success', 'message': 'å·²æ¸…ç©ºåˆ—è¡¨'})
    
    return jsonify({'status': 'error', 'message': 'æ— æ•ˆæ“ä½œ'})

@app.route('/api/capture_history')
def capture_history():
    return jsonify({
        'history': system.capture_history[-50:],
        'total_captures': len(system.capture_history)
    })

@app.route('/api/manual_capture', methods=['POST'])
def manual_capture():
    if system.current_frame is not None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"manual_capture_{timestamp}.jpg"
        filepath = os.path.join(system.auto_capture_dir, filename)
        
        cv2.imwrite(filepath, system.current_frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
        return jsonify({'status': 'success', 'message': f'æŠ“æ‹æˆåŠŸ: {filename}'})
    
    return jsonify({'status': 'error', 'message': 'æ— æ³•è·å–ç”»é¢'})

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨ç®€åŒ–ä¼˜åŒ–ç‰ˆWebæœåŠ¡å™¨...")
    print("ğŸ“± è®¿é—®åœ°å€: http://localhost:5000")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢")
    print("="*50)
    
    try:
        app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
    except KeyboardInterrupt:
        print("\næ­£åœ¨åœæ­¢ç³»ç»Ÿ...")
        system.stop_camera()
        print("ğŸ‘‹ ç³»ç»Ÿå·²åœæ­¢") 